{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this pipeline, we mainly implement the process of reloading the pretrained ResNet18, EfficientNet_B0, and DINOv2 (b/14) models to perform inference on the CIFAR-10 test set.\n",
        "\n",
        "The goal is to obtain the top-1 accuracy, confusion matrix, per-class accuracy, and UMAP visualization. I strongly recommend using a GPU to run this pipeline. Due to the inherent complexity of DINOv2 and the resource-intensive nature of generating UMAP visualizations, using a **GPU** is definitely a better choice.\n",
        "\n",
        "At the end of the pipeline, I included an optional feature for testing on a single input image. This part only requires loading the pretrained weights and does not involve any additional steps"
      ],
      "metadata": {
        "id": "wN6CDvpHjt1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and load model weights"
      ],
      "metadata": {
        "id": "SZcQamaUuDB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "!pip install -q gdown\n",
        "import gdown\n",
        "import zipfile\n",
        "import timm\n",
        "!pip install -q transformers\n",
        "from transformers import AutoModelForImageClassification\n",
        "from transformers.models.dinov2.modeling_dinov2 import Dinov2ForImageClassification"
      ],
      "metadata": {
        "id": "smlYL_lFJXtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file and unzip\n",
        "file_id = \"1--vYxuc0fRE7539StX1Ts9RkAw00_XiZ\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"cifar-10.zip\", quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(\"cifar-10.zip\", 'r') as zip_ref:\n",
        "    for member in zip_ref.namelist():\n",
        "        filename = os.path.relpath(member, start=\"content/drive/MyDrive/Model/\")\n",
        "        if filename.startswith(\"cifar-10\"):\n",
        "            zip_ref.extract(member, \"model\") #Save to local \"model\" folder\n",
        "            src_path = os.path.join(\"model\", member)\n",
        "            dst_path = os.path.join(\"model\", filename)\n",
        "            os.renames(src_path, dst_path)"
      ],
      "metadata": {
        "id": "pOPR0w1OtRug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the test set"
      ],
      "metadata": {
        "id": "pxdUWweqy7-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQGv2hq1JIrA"
      },
      "outputs": [],
      "source": [
        "# Set seed (For reproducibility)\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# cifar10 test set loading\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a general evaluation function"
      ],
      "metadata": {
        "id": "QIG9ynwzzezL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define confusion matrix, top1 accuracy and Per-class Accuracy"
      ],
      "metadata": {
        "id": "C--D0VPDzzHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, class_names, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            # If it is a huggingface model, there is a .logits attribute\n",
        "            if hasattr(outputs, 'logits'):\n",
        "              logits = outputs.logits\n",
        "            else:\n",
        "              logits = outputs\n",
        "            # Calculate predictions using the logits\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Top-1 Accuracy\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Top-1 Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    # Per-class Accuracy\n",
        "    cm_diagonal = cm.diagonal()\n",
        "    cm_counts = cm.sum(axis=1)\n",
        "    print(\"\\nPer-Class Accuracy:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_acc = cm_diagonal[i] / cm_counts[i] if cm_counts[i] > 0 else 0\n",
        "        print(f\"{class_name:15s}: {class_acc * 100:.2f}%\")\n",
        "\n",
        "    # UMAP Visualization\n",
        "    try:\n",
        "        import umap\n",
        "    except ImportError:\n",
        "        print(\"UMAP not installed, skipping feature visualization.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nProjecting features using UMAP...\")\n",
        "\n",
        "    # Recollect all features (logits) and labels\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, lbls in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            features.append(logits.cpu())\n",
        "            labels.extend(lbls.cpu().numpy())\n",
        "\n",
        "    features = torch.cat(features, dim=0).numpy()\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "    proj = reducer.fit_transform(features)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for class_idx in np.unique(labels):\n",
        "        idxs = labels == class_idx\n",
        "        plt.scatter(proj[idxs, 0], proj[idxs, 1], label=class_names[class_idx], s=10)\n",
        "    plt.legend(markerscale=2)\n",
        "    plt.title(\"UMAP Projection of Model Output Features\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aJ-5lreHzOH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate three models"
      ],
      "metadata": {
        "id": "USzXqm4gx0sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_classes=10 # For cifar-10, classes are 10"
      ],
      "metadata": {
        "id": "_EZ5wzTMyKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet-18 for CIFAR-10\n",
        "model = models.resnet18(num_classes = number_classes)\n",
        "model.load_state_dict(torch.load(\"/content/model/cifar-10/best_resnet18.pth\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "U9wCDTIPyXuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNet_B0 for CIFAR-10\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=False, num_classes=number_classes)\n",
        "model.load_state_dict(torch.load(\"/content/model/cifar-10/efficientnetb0_best.pth\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "jlIMt6Ey0Qhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define  new transform manually (mimics DINOv2 processor)\n",
        "# For dino v2, we resize (224,224) to train, so need resize\n",
        "\n",
        "\n",
        "\"\"\" I strongly recommend using GPU to calculate this section!!!!\"\"\"\n",
        "\n",
        "\n",
        "transform_dino = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DINOv2 expects 224×224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Reload test set with this transform\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_dino)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"facebook/dinov2-base\",\n",
        "    num_labels=10,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "state_dict = torch.load(\"/content/model/cifar-10/dinov2_finetuned_cifar10.pth\", map_location=\"cpu\")\n",
        "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"Missing keys:\", missing_keys)\n",
        "print(\"Unexpected keys:\", unexpected_keys)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "CiWYDLLOEzIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Single image input to get results"
      ],
      "metadata": {
        "id": "r2FxecRVsXgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the pipeline, I included an optional feature for testing on a single input image. This part only requires loading the pretrained weights and does not involve any additional steps"
      ],
      "metadata": {
        "id": "9Ut6Zdru3Qpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model\n",
        "def load_model(model_name, device, num_classes=10):\n",
        "    if model_name == \"resnet18\":\n",
        "        model = models.resnet18(num_classes=num_classes)\n",
        "        state_dict = torch.load(\"/content/model/cifar-10/best_resnet18.pth\", map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    elif model_name == \"efficientnet_b0\":\n",
        "        model = timm.create_model(\"efficientnet_b0\", pretrained=False, num_classes=num_classes)\n",
        "        state_dict = torch.load(\"/content/model/cifar-10/efficientnetb0_best.pth\", map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    elif model_name == \"dinov2\":\n",
        "        model = AutoModelForImageClassification.from_pretrained(\n",
        "            \"facebook/dinov2-base\",\n",
        "            num_labels=num_classes,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        state_dict = torch.load(\"/content/model/cifar-10/dinov2_finetuned_cifar10.pth\", map_location=device)\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type.\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Distinguish image processing methods for different models\n",
        "def get_transform(model_name):\n",
        "    if model_name == \"dinov2\":\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                 [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "# Predicting a single image\n",
        "def predict_single_image(model, image_path, device, class_names, transform):\n",
        "    model.eval()\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred = probs.argmax(dim=1).item()\n",
        "        confidence = probs[0, pred].item()\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Prediction: {class_names[pred]} ({confidence*100:.2f}%)\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.xlabel(\"Single Image Inference\")\n",
        "    plt.show()\n",
        "\n",
        "    return class_names[pred], confidence\n"
      ],
      "metadata": {
        "id": "rY2hVkq-sgBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "model_name = \"efficientnet_b0\" # input \"dinov2\" or \"resnet18\" or \"efficientnet_b0\"\n",
        "image_path = \"/content/sphynx04.jpg\" # input your the image path\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = load_model(model_name, device)\n",
        "transform = get_transform(model_name)\n",
        "\n",
        "predict_single_image(model, image_path, device, class_names, transform)\n"
      ],
      "metadata": {
        "id": "W_9Rf970wnXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}