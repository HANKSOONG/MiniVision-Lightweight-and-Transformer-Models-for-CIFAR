{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The workflow of this pipeline is largely similar to that of the CIFAR-10 pipeline. Its main purpose is to demonstrate the successful transfer of models trained on CIFAR-10 to CIFAR-100.\n",
        "\n",
        "I strongly recommend using a GPU to run this pipeline. Due to the inherent complexity of DINOv2 and the resource-intensive nature of generating UMAP visualizations, using a **GPU** is definitely a better choice."
      ],
      "metadata": {
        "id": "wN6CDvpHjt1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and load model weights"
      ],
      "metadata": {
        "id": "SZcQamaUuDB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "!pip install -q gdown\n",
        "import gdown\n",
        "import zipfile\n",
        "import timm\n",
        "!pip install -q transformers\n",
        "from transformers import AutoModelForImageClassification\n",
        "from transformers.models.dinov2.modeling_dinov2 import Dinov2ForImageClassification"
      ],
      "metadata": {
        "id": "smlYL_lFJXtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file and unzip\n",
        "file_id = \"1Qp063eb6V9tSmYsfnJOtNH_fMHCQ_I7M\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"cifar100.zip\", quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(\"cifar100.zip\", 'r') as zip_ref:\n",
        "    for member in zip_ref.namelist():\n",
        "        filename = os.path.relpath(member, start=\"content/drive/MyDrive/Model/\")\n",
        "        if filename.startswith(\"cifar100\"):\n",
        "            zip_ref.extract(member, \"model\") #Save to local \"model\" folder\n",
        "            src_path = os.path.join(\"model\", member)\n",
        "            dst_path = os.path.join(\"model\", filename)\n",
        "            os.renames(src_path, dst_path)"
      ],
      "metadata": {
        "id": "dmh8Ct0jpy5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the test set"
      ],
      "metadata": {
        "id": "pxdUWweqy7-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQGv2hq1JIrA"
      },
      "outputs": [],
      "source": [
        "# Set seed (For reproducibility)\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# cifar100 test set loading\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "test_set = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a general evaluation function"
      ],
      "metadata": {
        "id": "QIG9ynwzzezL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define confusion matrix, top1 accuracy and Per-class Accuracy"
      ],
      "metadata": {
        "id": "C--D0VPDzzHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, class_names, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            # If it is a huggingface model, there is a .logits attribute\n",
        "            if hasattr(outputs, 'logits'):\n",
        "              logits = outputs.logits\n",
        "            else:\n",
        "              logits = outputs\n",
        "            # Calculate predictions using the logits\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Top-1 Accuracy\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Top-1 Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    # Per-class Accuracy\n",
        "    cm_diagonal = cm.diagonal()\n",
        "    cm_counts = cm.sum(axis=1)\n",
        "    print(\"\\nPer-Class Accuracy:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_acc = cm_diagonal[i] / cm_counts[i] if cm_counts[i] > 0 else 0\n",
        "        print(f\"{class_name:15s}: {class_acc * 100:.2f}%\")\n",
        "\n",
        "    # UMAP Visualization\n",
        "    try:\n",
        "        import umap\n",
        "    except ImportError:\n",
        "        print(\"UMAP not installed, skipping feature visualization.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nProjecting features using UMAP...\")\n",
        "\n",
        "    # Recollect all features (logits) and labels\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, lbls in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            features.append(logits.cpu())\n",
        "            labels.extend(lbls.cpu().numpy())\n",
        "\n",
        "    features = torch.cat(features, dim=0).numpy()\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "    proj = reducer.fit_transform(features)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for class_idx in np.unique(labels):\n",
        "        idxs = labels == class_idx\n",
        "        plt.scatter(proj[idxs, 0], proj[idxs, 1], label=class_names[class_idx], s=10)\n",
        "    plt.legend(markerscale=2)\n",
        "    plt.title(\"UMAP Projection of Model Output Features\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aJ-5lreHzOH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate three models"
      ],
      "metadata": {
        "id": "USzXqm4gx0sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_classes=100 # For cifar-100, classes are 100"
      ],
      "metadata": {
        "id": "_EZ5wzTMyKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet-18 for CIFAR-10\n",
        "model = models.resnet18(num_classes = number_classes)\n",
        "model.load_state_dict(torch.load(\"/content/model/cifar100model/best_resnet18.pth\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# CIFAR-100 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "U9wCDTIPyXuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNet_B0 for CIFAR-100\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=False, num_classes=number_classes)\n",
        "model.load_state_dict(torch.load(\"/content/model/cifar100model/efficientnetb0_best.pth\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "jlIMt6Ey0Qhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define  new transform manually (mimics DINOv2 processor)\n",
        "# For dino v2, we resize (224,224) to train, so need resize\n",
        "\n",
        "\n",
        "\"\"\" I strongly recommend using GPU to calculate this section!!!!\"\"\"\n",
        "\n",
        "\n",
        "transform_dino = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DINOv2 expects 224×224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Reload test set with this transform\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_set = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_dino)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"facebook/dinov2-base\",\n",
        "    num_labels=100,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "state_dict = torch.load(\"/content/model/cifar100model/dinov2_finetuned_cifar100.pth\", map_location=\"cpu\")\n",
        "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"Missing keys:\", missing_keys)\n",
        "print(\"Unexpected keys:\", unexpected_keys)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# CIFAR-100 class names\n",
        "class_names = test_set.classes\n",
        "evaluate_model(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "CiWYDLLOEzIY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}