{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAk9lcz4tdo7"
      },
      "source": [
        "DINOv2 distilled\n",
        "(ViT-B/14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23zmVykztHsK"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rxYdl2ms4RC"
      },
      "outputs": [],
      "source": [
        "# Installation\n",
        "!pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q accelerate\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q torch torchvision transformers scikit-learn accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJi1blFZyDAi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from transformers import AutoImageProcessor, AutoModel, AutoModelForImageClassification\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import torch.optim as optim # import optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from umap import UMAP  # pip install umap-learn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOJ_3J3bvBs4"
      },
      "outputs": [],
      "source": [
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed to ensure reproducible results\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "NUkbthZ69DYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Only training a Linear Classifier"
      ],
      "metadata": {
        "id": "DRhxIYwR9n-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDkMQD3b22uM"
      },
      "outputs": [],
      "source": [
        "#transform (resize to 224)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ViT/DINOv2 require\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0zb2IzV3Dvb"
      },
      "outputs": [],
      "source": [
        "# dataset download\n",
        "full_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "val_ratio = 0.1\n",
        "val_size = int(len(full_train) * val_ratio)\n",
        "train_size = len(full_train) - val_size\n",
        "\n",
        "train_set, val_set = random_split(full_train, [train_size, val_size])\n",
        "\n",
        "# set vatch size\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvX6q4UF3O8q"
      },
      "outputs": [],
      "source": [
        "# Load DINOv2 model\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to device\n",
        "model = AutoModel.from_pretrained(\"facebook/dinov2-base\").to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDRbFmC03ass"
      },
      "outputs": [],
      "source": [
        "# Characteristic function (applicable to DataLoader)\n",
        "def extract_embeddings_from_dataset(dataset):\n",
        "  embeddings = []\n",
        "  labels = []\n",
        "\n",
        "  for img, label in tqdm(dataset):\n",
        "    # Reconstruct the PIL Image from the original image (tensor → PIL)\n",
        "    img = transforms.ToPILImage()(img)\n",
        "    inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "      cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "      embeddings.append(cls_token.cpu().numpy())\n",
        "      labels.append(label)\n",
        "\n",
        "  return np.vstack(embeddings), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAfmdF1y399e"
      },
      "outputs": [],
      "source": [
        "# Extract features\n",
        "train_embeddings, train_labels = extract_embeddings_from_dataset(train_set)\n",
        "val_embeddings, val_labels = extract_embeddings_from_dataset(val_set)\n",
        "test_embeddings, test_labels = extract_embeddings_from_dataset(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oeb6h8Nn4LI7"
      },
      "outputs": [],
      "source": [
        "# Training a Linear Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Validation set evaluation\n",
        "val_acc = (clf.predict(val_embeddings) == val_labels).mean()\n",
        "print(\"Validation Accuracy:\", round(val_acc * 100, 2), \"%\")\n",
        "\n",
        "# Test set evaluation\n",
        "test_acc = (clf.predict(test_embeddings) == test_labels).mean()\n",
        "print(\"Test Accuracy:\", round(test_acc * 100, 2), \"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3N6CGxCwZHA"
      },
      "source": [
        "# FINE-TUEN with Scheduler (Selective Fine-Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-PvYOR162I0"
      },
      "outputs": [],
      "source": [
        "#transform （keep in PIL foramt)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\"))  # Make sure it is in PIL format\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d832tAO1-apz"
      },
      "outputs": [],
      "source": [
        "# Customize collate_fn to keep the image format as is\n",
        "def collate_pil(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    return list(images), torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN3VYh9d74N1"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "# dataset download\n",
        "full_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "val_ratio = 0.1\n",
        "val_size = int(len(full_train) * val_ratio)\n",
        "train_size = len(full_train) - val_size\n",
        "\n",
        "train_set, val_set = random_split(full_train, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qTA489FxbnA"
      },
      "outputs": [],
      "source": [
        "# try batch size as 256, and use num_worker to accelerate\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, collate_fn=collate_pil, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=256, shuffle=False, collate_fn=collate_pil, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, collate_fn=collate_pil, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9pNcz90wgED"
      },
      "outputs": [],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Define device here\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"facebook/dinov2-base\",\n",
        "    num_labels=10,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "# Freeze selected layers BEFORE defining optimizer\n",
        "for name, param in model.named_parameters():\n",
        "    if \"encoder.layer\" in name:\n",
        "        layer_num = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n",
        "        if layer_num < 9:\n",
        "            param.requires_grad = False\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5) # use optim.AdamW\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize GradScaler for automatic mixed precision\n",
        "scaler = GradScaler() # Add this line to initialize GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5q8aeBh8L9d"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            inputs = processor(images=imgs, return_tensors=\"pt\").to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(**inputs)\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkN-GRyDyWg9"
      },
      "outputs": [],
      "source": [
        "best_val_acc = 0.0\n",
        "no_improvement = 0\n",
        "early_stop_patience = 5  # Set patience as 5 to prevent early stopping\n",
        "save_path = \"/content/drive/MyDrive/rec_model/dinov2/dinov2_finetuned_cifar10.pth\"\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "lr_history = []\n",
        "\n",
        "for epoch in range(40): # Beacause I already had early stopping, I used 40 to try\n",
        "    model.train()\n",
        "    # Initialize\n",
        "    total_loss = 0\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs = processor(images=imgs, return_tensors=\"pt\").to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(\"cuda\"):\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Train accuracy tracking\n",
        "        preds = outputs.logits.argmax(dim=1)\n",
        "        correct_train += (preds == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    train_acc = correct_train / total_train\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    # Log values\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    scheduler.step(val_acc)\n",
        "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Avg Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"[Epoch {epoch+1}] Current LR: {current_lr:.6f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        print(f\"New best val acc! Saving model to {save_path}\")\n",
        "        best_val_acc = val_acc\n",
        "        no_improvement = 0\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "        print(f\"No improvement for {no_improvement} epoch(s).\")\n",
        "\n",
        "    if no_improvement >= early_stop_patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model, \"/content/drive/MyDrive/rec_model/dinov2/dinov2_finetuned_entire_model.pt\")"
      ],
      "metadata": {
        "id": "0-b3pIheQTNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZQYMwF_DEth"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfBg-qUhbb34"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dWolp7Z8qA3"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_acc = evaluate(model, test_loader)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5XV95k3f136"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "log_df = pd.DataFrame({\n",
        "    \"epoch\": list(range(1, len(train_losses)+1)),\n",
        "    \"train_loss\": train_losses,\n",
        "    \"train_acc\": train_accuracies,\n",
        "    \"val_acc\": val_accuracies,\n",
        "    \"lr\": lr_history\n",
        "})\n",
        "\n",
        "log_df.to_csv(\"/content/drive/MyDrive/rec_model/dinov2/training_log.csv\", index=False)\n",
        "log_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Loading model output results"
      ],
      "metadata": {
        "id": "s__0Xojg-6AK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLwCEiC75m8V"
      },
      "outputs": [],
      "source": [
        "# Loading model output results\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"facebook/dinov2-base\",\n",
        "    num_labels=10,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "# Load finetuned weight\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/rec_model/dinov2/dinov2_finetuned_cifar10.pth\"))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVC8Ewfm7NlC"
      },
      "outputs": [],
      "source": [
        "# try batch size as 256, and use num_worker to accelerate\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, collate_fn=collate_pil, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=256, shuffle=False, collate_fn=collate_pil, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, collate_fn=collate_pil, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfEpQOiT51PR"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Get a batch from test set\n",
        "imgs, labels = next(iter(test_loader))\n",
        "imgs = list(imgs)\n",
        "labels = labels.tolist()\n",
        "\n",
        "# Select 30 random samples\n",
        "indices = random.sample(range(len(imgs)), 30)\n",
        "selected_imgs = [imgs[i] for i in indices]\n",
        "true_labels = [labels[i] for i in indices]\n",
        "\n",
        "# Inference\n",
        "inputs = processor(images=selected_imgs, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    preds = outputs.logits.argmax(dim=1).cpu().tolist()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i, img in enumerate(selected_imgs):\n",
        "    plt.subplot(3, 10, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'{class_names[true_labels[i]]}→{class_names[preds[i]]}', fontsize=8)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"DINOv2 Predictions on Test Images (30 samples)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/drive/MyDrive/rec_model/dinov2/dinov2_pred_30.png\", dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxjSu5PF6o7p"
      },
      "outputs": [],
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in test_loader:\n",
        "        inputs = processor(images=imgs, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Access the base model's forward method to get hidden states\n",
        "        # This assumes the AutoModelForImageClassification has an attribute\n",
        "        # that is the base model (e.g., 'vit' or similar depending on the architecture).\n",
        "        # For DINOv2, the base model is often named 'vit'.\n",
        "        # Let's try accessing model.dinov2 or model.vit\n",
        "        # Based on the model structure, 'dinov2' is likely the correct attribute.\n",
        "        base_outputs = model.dinov2(**inputs)\n",
        "\n",
        "        # Now base_outputs should have last_hidden_state\n",
        "        cls_token = base_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "        features.append(cls_token.cpu())\n",
        "        labels.extend(lbls.cpu().tolist())\n",
        "\n",
        "features = torch.cat(features).numpy()\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Extracted features shape: {features.shape}\")\n",
        "print(f\"Extracted labels shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCuxuMbO7IMj"
      },
      "outputs": [],
      "source": [
        "# UMAP projection of dinov2\n",
        "reducer = UMAP(n_components=2, random_state=42)\n",
        "proj = reducer.fit_transform(features)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "for class_idx in np.unique(labels):\n",
        "    idx = labels == class_idx\n",
        "    plt.scatter(proj[idx, 0], proj[idx, 1], label=class_names[class_idx], s=10)\n",
        "plt.legend()\n",
        "plt.title(\"UMAP Projection of DINOv2 CLS Features\")\n",
        "plt.xlabel(\"UMAP Feature 1\")\n",
        "plt.ylabel(\"UMAP Feature 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/rec_model/dinov2/dinov2_umap.png', dpi=300)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}